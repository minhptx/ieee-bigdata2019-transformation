{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transformation Experiments\n",
    "\n",
    "## This notebook presents a set of experiments running for data transformation.\n",
    "## First, we need to set up the environment and observers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from beakerx import *\n",
    "from beakerx.object import beakerx\n",
    "\n",
    "from sacred import Experiment\n",
    "from sacred.observers import MongoObserver\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "beakerx.pandas_display_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The set of following functions below supports running these expriments.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datafc.evaluation import Evaluator\n",
    "\n",
    "data_folder = Path(\"../../data/standard\")\n",
    "ex = Experiment(\"jupyter_ex\", interactive=True)\n",
    "ex.observers.append(MongoObserver.create())\n",
    "\n",
    "\n",
    "def run_scenario(\n",
    "    evaluator, scenario_folder, mapping_method, string_similarity, with_flashfill\n",
    "):\n",
    "    original_values = []\n",
    "    target_values = []\n",
    "    groundtruth_values = []\n",
    "\n",
    "    for file in scenario_folder.iterdir():\n",
    "        with file.open(encoding=\"utf-8\") as reader:\n",
    "\n",
    "            for row in reader.readlines():\n",
    "                row = row.encode(\"utf-8\").decode(\"ascii\", \"ignore\")\n",
    "                if \"input\" in file.name:\n",
    "                    original_values.append(row.strip())\n",
    "                if \"transformed\" in file.name:\n",
    "                    target_values.append(row.strip())\n",
    "                if \"groundtruth\" in file.name:\n",
    "                    groundtruth_values.append(row.strip())\n",
    "\n",
    "    evaluator.run_active_top_k_experiment(\n",
    "        scenario_folder.name,\n",
    "        original_values[:1000],\n",
    "        target_values[:1000],\n",
    "        groundtruth_values[:1000],\n",
    "        10,\n",
    "        with_flashfill=with_flashfill,\n",
    "    )\n",
    "\n",
    "    scenario_report = evaluator.generate_scenario_report(scenario_folder.name, 10)\n",
    "    return scenario_report\n",
    "\n",
    "\n",
    "@ex.main\n",
    "def run_dataset(dataset, mapping_method, mapping_features, with_flashfill):\n",
    "    evaluator = Evaluator(mapping_method, mapping_features)\n",
    "    scenario_reports = []\n",
    "\n",
    "    for scenario_folder in tqdm((data_folder / f\"{dataset}\").iterdir()):\n",
    "        scenario_report = run_scenario(\n",
    "            evaluator, scenario_folder, mapping_method, mapping_features, with_flashfill\n",
    "        )\n",
    "        scenario_reports.append(scenario_report)\n",
    "\n",
    "    dataset_report = evaluator.generate_dataset_report(dataset, 10)\n",
    "    dataset_report[\"scenarios\"] = scenario_reports\n",
    "    return dataset_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results are added to MongoDB for experiment reproduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - root - Added new config entry: \"dataset\"\n",
      "WARNING - root - Added new config entry: \"mapping_features\"\n",
      "WARNING - root - Added new config entry: \"mapping_method\"\n",
      "WARNING - root - Added new config entry: \"with_flashfill\"\n",
      "INFO - jupyter_ex - Running command 'run_dataset'\n",
      "INFO - jupyter_ex - Started run with ID \"28\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a818ca6741364003a2b2d8ca646f10c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = \"museum\"\n",
    "mapping_method = \"sim\"\n",
    "mapping_features = [\"jaccard\"]\n",
    "with_flashfill = False\n",
    "\n",
    "hyper_params = {\n",
    "    \"dataset\": dataset,\n",
    "    \"mapping_method\": mapping_method,\n",
    "    \"mapping_features\": mapping_features,\n",
    "    \"with_flashfill\": with_flashfill,\n",
    "}\n",
    "\n",
    "dataset_report = ex.run(config_updates=hyper_params).result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios_df = pd.DataFrame(dataset_report[\"scenarios\"], columns=[\"name\", \"running_time\", \"active_learning_curve\"]).round(2)\n",
    "\n",
    "scenarios_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
